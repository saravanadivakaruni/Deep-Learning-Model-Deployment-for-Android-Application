{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploying a face unmasking deep learning model for android application.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DEPLOYING THE MODEL**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EGj4kPLu5OHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVE AND LOAD THE MODEL TO USE IT AS SAVED MODEL"
      ],
      "metadata": {
        "id": "8BROy-nGqFps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "!pip install tflite-runtime"
      ],
      "metadata": {
        "id": "ZfuzYXPXl3KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ea315e-b0a7-44fb-c317-4064d3a87187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.8.0-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tflite-runtime) (1.21.6)\n",
            "Installing collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.saved_model.save(model, path_to_dir) #SAVING THE MODEL\n",
        "!cd /content/drive/MyDrive/SDP/saved_model\n",
        "model = tf.saved_model.load ('/content/drive/MyDrive/SDP/saved_model')"
      ],
      "metadata": {
        "id": "ky2lmNVZqLXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERTING MODEL FROM TENSORFLOW TO TENSORFLOW LITE"
      ],
      "metadata": {
        "id": "HffWYdBSItgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(tf.Module):\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32)])\n",
        "  def encode(self, x):\n",
        "    result = tf.strings.as_string(x)\n",
        "    return {\n",
        "         \"encoded_result\": result\n",
        "    }\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string)])\n",
        "  def decode(self, x):\n",
        "    result = tf.strings.to_number(x)\n",
        "    return {\n",
        "         \"decoded_result\": result\n",
        "    }"
      ],
      "metadata": {
        "id": "ghUY4QJM-4SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "\n",
        "# Save the model\n",
        "SAVED_MODEL_PATH = '/content/drive/MyDrive/SDP/saved_model'\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model, SAVED_MODEL_PATH,\n",
        "    signatures={\n",
        "      'encode': model.encode.get_concrete_function(),\n",
        "      'decode': model.decode.get_concrete_function()\n",
        "    })\n",
        "\n",
        "# Convert the saved model using TFLiteConverter\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Print the signatures from the converted model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "signatures = interpreter.get_signature_list()\n",
        "print(signatures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPG6e_S1tAiP",
        "outputId": "e92a33f4-830c-4147-9c0a-819c21510d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/SDP/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decode': {'inputs': ['x'], 'outputs': ['decoded_result']}, 'encode': {'inputs': ['x'], 'outputs': ['encoded_result']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model.\n",
        "with open('Unmask_the_masked.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "lQxluZG9_WcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}